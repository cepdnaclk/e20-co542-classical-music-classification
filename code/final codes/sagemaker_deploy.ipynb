{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Real-Time Deployment (GTZAN CNN)\n",
    "\n",
    "This notebook packages model artifacts, uploads to S3, and deploys a real-time endpoint using `inference.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these paths if needed\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_SRC = Path('..') / 'models'\n",
    "PROCESSED_DIR = Path('..') / 'data' / 'processed'\n",
    "MODEL_TAR = Path('model.tar.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package model artifacts into model.tar.gz\n",
    "import tarfile\n",
    "\n",
    "model_dir = Path('model')\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "(model_dir / 'gtzan_cnn.h5').write_bytes((MODEL_SRC / 'gtzan_cnn.h5').read_bytes())\n",
    "(model_dir / 'mfcc_mean.npy').write_bytes((MODEL_SRC / 'mfcc_mean.npy').read_bytes())\n",
    "(model_dir / 'mfcc_std.npy').write_bytes((MODEL_SRC / 'mfcc_std.npy').read_bytes())\n",
    "(model_dir / 'classes.npy').write_bytes((PROCESSED_DIR / 'classes.npy').read_bytes())\n",
    "\n",
    "with tarfile.open(MODEL_TAR, 'w:gz') as tar:\n",
    "    tar.add(model_dir, arcname='.')\n",
    "\n",
    "print('Wrote', MODEL_TAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model.tar.gz to S3\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'gtzan-cnn'\n",
    "model_s3 = sess.upload_data(str(MODEL_TAR), bucket=bucket, key_prefix=prefix)\n",
    "print(model_s3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy real-time endpoint\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "model = TensorFlowModel(\n",
    "    model_data=model_s3,\n",
    "    role=role,\n",
    "    framework_version='2.13',\n",
    "    py_version='py310',\n",
    "    entry_point='inference.py',\n",
    "    source_dir='.',\n",
    ")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    ")\n",
    "\n",
    "print('Endpoint:', predictor.endpoint_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke endpoint with a WAV file\n",
    "import boto3\n",
    "\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "with open('sample.wav', 'rb') as f:\n",
    "    payload = f.read()\n",
    "\n",
    "resp = runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint_name,\n",
    "    ContentType='audio/wav',\n",
    "    Body=payload,\n",
    ")\n",
    "\n",
    "print(resp['Body'].read().decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup (optional)\n",
    "# predictor.delete_endpoint()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}